{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jutHpud0rz04"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pandasai import PandasAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqQoqSborz08"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "from langchain import PromptTemplate, LLMChain\n",
        "from langchain.callbacks.manager import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.agents import create_pandas_dataframe_agent\n",
        "from langchain.prompts.chat import (\n",
        "    ChatPromptTemplate,\n",
        "    SystemMessagePromptTemplate,\n",
        "    HumanMessagePromptTemplate,\n",
        ")\n",
        "from pandasai.llm import LangchainLLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O35ci0ROrz09"
      },
      "outputs": [],
      "source": [
        "# Callbacks support token-wise streaming\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "# Verbose is required to pass to the callback manager\n",
        "# Make sure the model path is correct for your system!\n",
        "# .gguf for llama-cpp-python after 0.1.79\n",
        "llama_lc = LlamaCpp(\n",
        "    model_path=\"./wizardcoder-python-34b-v1.0.Q4_K_S.gguf\",\n",
        "    callback_manager=callback_manager,\n",
        "    verbose=False,n_ctx=4096*4,\n",
        "    n_gpu_layers=20,\n",
        "    n_batch=20,\n",
        "    streaming=True,\n",
        ")\n",
        "llama = LangchainLLM(llama_lc)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-t6bSe8rz0-"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('iris.csv')\n",
        "agent = create_pandas_dataframe_agent(llama_lc, df, verbose=False,handle_parsing_errors=\"Check your output and make sure it conforms!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3dTiVntrz0_",
        "outputId": "b1717941-a654-4772-adef-6ecbf23bb722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-08-29 12:17:49 [INFO] Question: scatter plot of sepallength vs sepalwidth color by class\n",
            "2023-08-29 12:17:49 [INFO] Running PandasAI with langchain_llama.cpp LLM...\n",
            "2023-08-29 12:17:49 [INFO] Prompt ID: 6fb21810-ffb3-44c4-891c-fdb9ec98d3b1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "```python\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import os\n",
            "from pathlib import Path\n",
            "\n",
            "\n",
            "def analyze_data(dfs):\n",
            "    df = dfs[0]\n",
            "    # Preprocessing and cleaning data if necessary\n",
            "    \n",
            "    # Processing: Manipulating data for analysis (grouping, filtering, aggregating, etc.)\n",
            "    groups = df.groupby('class')\n",
            "    \n",
            "    # Analyze: Conducting the actual analysis\n",
            "    fig, ax = plt.subplots()\n",
            "    for name, group in groups:\n",
            "        ax.scatter(group['sepallength'], group['sepalwidth'], label=name)\n",
            "        \n",
            "    ax.legend()\n",
            "    \n",
            "    # Save the plot to an image and return a dictionary with type and path of the plot as value\n",
            "    fig.savefig('exports/charts/temp_chart.png')\n",
            "    plt.close(fig)\n",
            "    result = {\"type\": \"plot\", \"value\": os.path.abspath('exports/charts/temp_chart.png')}\n",
            "    \n",
            "    return result\n",
            "``` 2023-08-29 12:20:41 [INFO] \n",
            "                    Code generated:\n",
            "                    ```\n",
            "                    import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "import os\n",
            "from pathlib import Path\n",
            "\n",
            "\n",
            "def analyze_data(dfs):\n",
            "    df = dfs[0]\n",
            "    # Preprocessing and cleaning data if necessary\n",
            "    \n",
            "    # Processing: Manipulating data for analysis (grouping, filtering, aggregating, etc.)\n",
            "    groups = df.groupby('class')\n",
            "    \n",
            "    # Analyze: Conducting the actual analysis\n",
            "    fig, ax = plt.subplots()\n",
            "    for name, group in groups:\n",
            "        ax.scatter(group['sepallength'], group['sepalwidth'], label=name)\n",
            "        \n",
            "    ax.legend()\n",
            "    \n",
            "    # Save the plot to an image and return a dictionary with type and path of the plot as value\n",
            "    fig.savefig('exports/charts/temp_chart.png')\n",
            "    plt.close(fig)\n",
            "    result = {\"type\": \"plot\", \"value\": os.path.abspath('exports/charts/temp_chart.png')}\n",
            "    \n",
            "    return result\n",
            "                    ```\n",
            "                \n",
            "2023-08-29 12:20:41 [WARNING] Failed to execute code with a correction framework [retry number: 1]\n",
            "2023-08-29 12:20:41 [INFO] Failed with error: Generated code includes import of os which is not in whitelist.. Retrying\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =  4789.46 ms\n",
            "llama_print_timings:      sample time =   121.06 ms /   246 runs   (    0.49 ms per token,  2032.12 tokens per second)\n",
            "llama_print_timings: prompt eval time = 82945.59 ms /   414 tokens (  200.35 ms per token,     4.99 tokens per second)\n",
            "llama_print_timings:        eval time = 87906.56 ms /   245 runs   (  358.80 ms per token,     2.79 tokens per second)\n",
            "llama_print_timings:       total time = 171753.38 ms\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/hho/miniconda3/envs/data_agent/lib/python3.9/site-packages/pandasai/smart_datalake/__init__.py\", line 314, in chat\n",
            "    result = self._code_manager.execute_code(\n",
            "  File \"/home/hho/miniconda3/envs/data_agent/lib/python3.9/site-packages/pandasai/helpers/code_manager.py\", line 176, in execute_code\n",
            "    code_to_run = self._clean_code(code)\n",
            "  File \"/home/hho/miniconda3/envs/data_agent/lib/python3.9/site-packages/pandasai/helpers/code_manager.py\", line 325, in _clean_code\n",
            "    self._check_imports(node)\n",
            "  File \"/home/hho/miniconda3/envs/data_agent/lib/python3.9/site-packages/pandasai/helpers/code_manager.py\", line 390, in _check_imports\n",
            "    raise BadImportError(library)\n",
            "pandasai.exceptions.BadImportError: Generated code includes import of os which is not in whitelist.\n",
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here's the corrected code without importing os:\n",
            "import pandas as pd\n",
            "import matplotlib.pyplot as plt\n",
            "\n",
            "from pathlib import Path\n",
            "\n",
            "def analyze_data(dfs):\n",
            "    df = dfs[0]\n",
            "    \n",
            "    # Preprocessing and cleaning data if necessary\n",
            "    \n",
            "    # Processing: Manipulating data for analysis (grouping, filtering, aggregating, etc.)\n",
            "    groups = df.groupby('class')\n",
            "    \n",
            "    # Analyze: Conducting the actual analysis\n",
            "    fig, ax = plt.subplots()\n",
            "    for name, group in groups:\n",
            "        ax.scatter(group['sepallength'], group['sepalwidth'], label=name)\n",
            "        \n",
            "    ax.legend()\n",
            "    \n",
            "    # Save the plot to an image and return a dictionary with type and path of the plot as value\n",
            "    fig.savefig('exports/charts/temp_chart.png')\n",
            "    plt.close(fig)\n",
            "    result = {\"type\": \"plot\", \"value\": Path('exports/charts/temp_chart.png').absolute()}\n",
            "    \n",
            "    return result Unfortunately, I was not able to answer your question, because of the following error:\n",
            "\n",
            "No code found in the response\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "llama_print_timings:        load time =  4789.46 ms\n",
            "llama_print_timings:      sample time =   130.00 ms /   246 runs   (    0.53 ms per token,  1892.26 tokens per second)\n",
            "llama_print_timings: prompt eval time = 100740.42 ms /   491 tokens (  205.17 ms per token,     4.87 tokens per second)\n",
            "llama_print_timings:        eval time = 88352.43 ms /   245 runs   (  360.62 ms per token,     2.77 tokens per second)\n",
            "llama_print_timings:       total time = 190059.54 ms\n"
          ]
        }
      ],
      "source": [
        "from pandasai import SmartDataframe\n",
        "prompt = \"scatter plot of sepallength vs sepalwidth color by class\"\n",
        "llama_pandasai = PandasAI(llm=llama, conversational=True,verbose=True)\n",
        "response = llama_pandasai.run(df, prompt=prompt)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mNiThNYTrz1A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}